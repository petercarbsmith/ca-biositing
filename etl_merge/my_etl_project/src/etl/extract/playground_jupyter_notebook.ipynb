{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Install prefect into the current Jupyter kernel environment\n",
    "!{sys.executable} -m pip install prefect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- Setup Project Environment ---\n",
    "\n",
    "# Define absolute paths for clarity\n",
    "project_root = '/Users/pjsmitty301/ca-biositing'\n",
    "etl_project_dir = os.path.join(project_root, 'etl_merge/my_etl_project')\n",
    "src_path = os.path.join(etl_project_dir, 'src')\n",
    "\n",
    "# Add the project's 'src' directory to the Python path for imports\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# --- Run Your Code in the Correct Context ---\n",
    "\n",
    "# Temporarily change the current working directory\n",
    "# This is important so the script can find the 'credentials.json' file\n",
    "original_dir = os.getcwd()\n",
    "os.chdir(etl_project_dir)\n",
    "\n",
    "print(f\"Temporarily changed CWD to: {os.getcwd()}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Now, import and run your function.\n",
    "# The @task decorator is ignored when calling the function directly.\n",
    "from etl.extract.basic_sample_info import extract_basic_sample_info\n",
    "\n",
    "print(\"Attempting to extract data...\")\n",
    "df = extract_basic_sample_info()\n",
    "\n",
    "# Good practice: change back to the original directory\n",
    "os.chdir(original_dir)\n",
    "print(f\"\\nRestored CWD to: {os.getcwd()}\")\n",
    "\n",
    "# --- Display Results ---\n",
    "if df is not None:\n",
    "    print(\"\\nData extracted successfully! Displaying the first 5 rows:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"\\nExtraction failed. Please double-check the console output.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can now work with the 'df' DataFrame below.\n",
    "# For example, to see the columns, run: df.columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomass_df1 = df[[\"Material_type\", \"Primary_crop\"]]\n",
    "biomass_df1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlmodel import Session, select\n",
    "from database import engine  # Import the engine from your project's database module\n",
    "from models.biomass import PrimaryProduct # Import the model for the table you want to query\n",
    "\n",
    "print(\"Querying the database for primary products...\")\n",
    "\n",
    "# Use a session to connect to the database\n",
    "with Session(engine) as session:\n",
    "    # Create a statement to select all from the primary_product table\n",
    "    statement = select(PrimaryProduct)\n",
    "    \n",
    "    # Use pandas to execute the query and load results into a DataFrame\n",
    "    products_df = pd.read_sql(statement, session.connection())\n",
    "\n",
    "print(\"Successfully loaded data from the 'primary_product' table.\")\n",
    "display(products_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.extract.basic_sample_info import extract_basic_sample_info\n",
    "\n",
    "df1 = extract_basic_sample_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[\"Material_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.extract.experiments import extract_experiments\n",
    "\n",
    "df1 = extract_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[[\"Analysis_type\", \"Analysis_abbrev\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
